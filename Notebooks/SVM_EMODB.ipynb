{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa \n",
    "from librosa import feature\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import re #split strings\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "fn_list_i = [\n",
    " feature.chroma_stft,\n",
    " feature.spectral_centroid,\n",
    " feature.spectral_bandwidth,\n",
    " feature.spectral_rolloff\n",
    "]\n",
    " \n",
    "fn_list_ii = [\n",
    " feature.zero_crossing_rate\n",
    "]\n",
    "#feature.rmse,\n",
    "\n",
    "emotions={ #german language\n",
    "    'W':'anger',\n",
    "    'L':'boredom',\n",
    "    'E':'disgust',\n",
    "    'A':'anxiety/fear',# *1\n",
    "    'F':'happiness',# *0\n",
    "    'T':'sadness',# *1\n",
    "    'N':'neutral',# *0\n",
    "}\n",
    "\n",
    "# Not stressed: happy(2), calm(1).\n",
    "# Stressed:     sad(3), fearful(5)\n",
    "stress_emotions = {\n",
    "    'F':0,\n",
    "    'N':0,\n",
    "    'A':1,\n",
    "    'T':1\n",
    "}\n",
    "selected_emotions = {'F','N','A','T'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocesamiento de corpus\n",
    "def preprocessing_data(filename):\n",
    "    # 1) audio: mono \n",
    "    # 2) frecuencia de muestreo(SR): 16000Hz\n",
    "    data, sr = librosa.load(filename, sr=16000, mono=True)\n",
    "    #3) normalizacion\n",
    "    X_scale = preprocessing.normalize([data])[0]\n",
    "    #plot_data(normalizado, sr)\n",
    "    #TODO: otros: farming, windowing, Voice Activity Detector (VAD), noise reduction,\n",
    "    return [X_scale, sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X_file_data = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X_file_data))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X_file_data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))#concatena ([1,2][3,4]) => [1,2,3,4]\n",
    "            \n",
    "            mfccs_var = np.var(librosa.feature.mfcc(y=X_file_data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs_var)) \n",
    "            \n",
    "            mfccs_std = np.std(librosa.feature.mfcc(y=X_file_data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs_std)) \n",
    "    \n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X_file_data, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X_file_data), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    #for file in glob.glob(\"/media/y/730D-8298/DATASETS/ravdess_test/Actor_*/*.wav\"): #* PC\n",
    "    for file in glob.glob(\"/media/y/730D-8298/DATASETS/Emo-DB/wav/*.wav\"): #* PC\n",
    "        file_name = os.path.basename(file) #            03-01-01-01-01-01-01.wav\n",
    "        print('File:  %s' % (file_name), end='\\r')\n",
    "        file_name_no_type = file_name.split(\".\")[0] #   03-01-01-01-01-01-01\n",
    "        #list_emotions = file_name_no_type.split(\"-\") #  ['03', '01', '01', '01', '01', '01', '01']\n",
    "        emotion = file_name_no_type[5]\n",
    "        \n",
    "        if emotion in selected_emotions:\n",
    "            e = stress_emotions[emotion]\n",
    "           \n",
    "            #signal, sample_rate = preprocessing_data(file)\n",
    "            feature = extract_feature(file, chroma=True, mfcc=True, mel=True, contrast=True, tonnetz=True) #get_feature_vector(signal, sample_rate)#extract_feature(file, mfcc=True) #TODO: add more features\n",
    "            x.append(feature)\n",
    "            y.append(e)\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  08a01Fd.wav\n",
      "\n",
      "X_data: (281, 273) Y_data: (281,)\n"
     ]
    }
   ],
   "source": [
    "X_data,Y_data = load_data()\n",
    "print(\"\\n\")\n",
    "print(\"X_data:\", X_data.shape, \"Y_data:\",  Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizaci贸n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data: (281, 273) Y_data: (281,)\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X_data)\n",
    "Y = Y_data \n",
    "print(\"X_data:\", X.shape, \"Y_data:\",  Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducci贸n de dimensionalidad con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data: (281, 150) Y_data: (281,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X =  PCA(n_components=150).fit_transform(X)\n",
    "print(\"X_data:\", X.shape, \"Y_data:\",  Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No estresados: 150 | Estresados: 131\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estresados = Y.sum()\n",
    "no_estresados = Y.shape[0]-estresados\n",
    "print(\"No estresados:\",no_estresados, \"| Estresados:\", estresados)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = Y\n",
    "plt.hist(data)\n",
    "plt.title('0: No Estresado | 1: Estresado', fontsize=10)\n",
    "#plt.savefig(\"Estres_NoEstres.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divisi贸n de datos: Entrenamiento, validaci贸n y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (196, 150) (196,) val & Test: (85, 150) (85,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=80) \n",
    "#X_val, X_test, Y_val, Y_test = train_test_split(X_val_test,Y_val_test, test_size=0.5, random_state=60)\n",
    "#print(\"Train:\", X_train.shape, Y_train.shape, \"Val:\", X_val.shape, Y_val.shape, \"Test:\", X_test.shape, Y_test.shape)\n",
    "print(\"Train:\", X_train.shape, Y_train.shape, \"val & Test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, gamma='auto', random_state=0, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM lineal\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_SVC = SVC(C=100.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "          probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "          verbose=0, max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
    "clf_SVC.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear SVC on training set: 0.99\n",
      "Accuracy of linear SVC on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "clf_SVC.fit(X_train,Y_train)\n",
    "print('Accuracy of linear SVC on training set: {:.2f}'.format(clf_SVC.score(X_train, Y_train)))\n",
    "print('Accuracy of linear SVC on test set: {:.2f}'.format(clf_SVC.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the generated array of c values\n",
      "[1.00000000e+00 1.07252413e+00 1.15030800e+00 1.23373308e+00\n",
      " 1.32320850e+00 1.41917304e+00 1.52209732e+00 1.63248610e+00\n",
      " 1.75088073e+00 1.87786182e+00 2.01405211e+00 2.16011948e+00\n",
      " 2.31678026e+00 2.48480272e+00 2.66501086e+00 2.85828845e+00\n",
      " 3.06558332e+00 3.28791207e+00 3.52636502e+00 3.78211156e+00\n",
      " 4.05640590e+00 4.35059319e+00 4.66611616e+00 5.00452215e+00\n",
      " 5.36747075e+00 5.75674188e+00 6.17424455e+00 6.62202624e+00\n",
      " 7.10228290e+00 7.61736977e+00 8.16981285e+00 8.76232139e+00\n",
      " 9.39780109e+00 1.00793684e+01 1.08103658e+01 1.15943781e+01\n",
      " 1.24352503e+01 1.33371059e+01 1.43043679e+01 1.53417796e+01\n",
      " 1.64544288e+01 1.76477719e+01 1.89276611e+01 2.03003732e+01\n",
      " 2.17726400e+01 2.33516817e+01 2.50452420e+01 2.68616263e+01\n",
      " 2.88097423e+01 3.08991436e+01 3.31400770e+01 3.55435321e+01\n",
      " 3.81212958e+01 4.08860094e+01 4.38512315e+01 4.70315038e+01\n",
      " 5.04424225e+01 5.41007151e+01 5.80243221e+01 6.22324854e+01\n",
      " 6.67458420e+01 7.15865259e+01 7.67782761e+01 8.23465535e+01\n",
      " 8.83186653e+01 9.47238993e+01 1.01593667e+02 1.08961659e+02\n",
      " 1.16864008e+02 1.25339468e+02 1.34429604e+02 1.44178993e+02\n",
      " 1.54635449e+02 1.65850250e+02 1.77878394e+02 1.90778869e+02\n",
      " 2.04614940e+02 2.19454460e+02 2.35370203e+02 2.52440221e+02\n",
      " 2.70748227e+02 2.90384006e+02 3.11443852e+02 3.34031045e+02\n",
      " 3.58256355e+02 3.84238584e+02 4.12105151e+02 4.41992717e+02\n",
      " 4.74047853e+02 5.08427759e+02 5.45301038e+02 5.84848519e+02\n",
      " 6.27264147e+02 6.72755931e+02 7.21546967e+02 7.73876530e+02\n",
      " 8.30001249e+02 8.90196364e+02 9.54757077e+02 1.02400000e+03]\n"
     ]
    }
   ],
   "source": [
    "#tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "c_SVC = np.logspace(start = 0, stop = 10, num = 100, base = 2 , dtype = 'float64')\n",
    "print( 'the generated array of c values')\n",
    "print ( c_SVC )\n",
    "param_grid_S = {'C': c_SVC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Array of means \n",
      "\n",
      "[0.785      0.785      0.785      0.79       0.79055556 0.79055556\n",
      " 0.79555556 0.79555556 0.80055556 0.81055556 0.81055556 0.81055556\n",
      " 0.81055556 0.81055556 0.82611111 0.82611111 0.83111111 0.83666667\n",
      " 0.83666667 0.84666667 0.85222222 0.85222222 0.85222222 0.85722222\n",
      " 0.85722222 0.85722222 0.85722222 0.86222222 0.86777778 0.86777778\n",
      " 0.86222222 0.86222222 0.86222222 0.85722222 0.85722222 0.86222222\n",
      " 0.86222222 0.85722222 0.86722222 0.87222222 0.86722222 0.87222222\n",
      " 0.86722222 0.86222222 0.86722222 0.86722222 0.86722222 0.87222222\n",
      " 0.87222222 0.87222222 0.87222222 0.86611111 0.86611111 0.85555556\n",
      " 0.86611111 0.86611111 0.87111111 0.87111111 0.88111111 0.87611111\n",
      " 0.88111111 0.88111111 0.88111111 0.88611111 0.88611111 0.89111111\n",
      " 0.89611111 0.90166667 0.90166667 0.90166667 0.90666667 0.90111111\n",
      " 0.89611111 0.90166667 0.89666667 0.89666667 0.89666667 0.90222222\n",
      " 0.90222222 0.89166667 0.89166667 0.89166667 0.89166667 0.89166667\n",
      " 0.88666667 0.88666667 0.88666667 0.88666667 0.88666667 0.88666667\n",
      " 0.88666667 0.88666667 0.88666667 0.88666667 0.88666667 0.88666667\n",
      " 0.88666667 0.88666667 0.88666667 0.88666667]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Array of means \\n\")\n",
    "clf = GridSearchCV(clf_SVC, param_grid =param_grid_S, cv=20 , scoring='accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88        45\n",
      "           1       0.91      0.80      0.85        40\n",
      "\n",
      "    accuracy                           0.87        85\n",
      "   macro avg       0.88      0.87      0.87        85\n",
      "weighted avg       0.87      0.87      0.87        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
